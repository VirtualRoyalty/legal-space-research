{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../DATASET.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"texts.txt\", \"w\") as f:\n",
    "    for x in df['text'].tolist():\n",
    "        f.write(x + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 45M words\n",
      "Number of words:  188467\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   34612 lr:  0.000000 loss:  0.752368 ETA:   0h 0m\n"
     ]
    }
   ],
   "source": [
    "!./fastText-0.2.0/fasttext cbow -input texts.txt -output cbow_model/model -wordNgrams 2 -epoch 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    return np.array(arr) / np.linalg.norm(arr)\n",
    "\n",
    "def read_word_emb(path):    \n",
    "    emb = {}\n",
    "    with open(path, \"r\") as m:\n",
    "        n, dim = tuple(map(int, m.readline().split()))\n",
    "        for l in m:\n",
    "            line = l.split()\n",
    "            emb[line[0]] = normalize([float(x) for x in line[1:]])\n",
    "    assert n == len(emb)\n",
    "    return emb\n",
    "\n",
    "emb = read_word_emb(\"cbow_model/model.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_emb(text):\n",
    "    \"\"\"Returns mean embedding vector of all word embedding vectors in text\"\"\"\n",
    "    res = []\n",
    "    for w in text.split():\n",
    "        if w in emb:\n",
    "            res.append(emb[w])\n",
    "    return np.mean(res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Фонды\n",
      "1. Общие положения\n",
      "1. Основные положения\n",
      "1. Основные положения\n"
     ]
    }
   ],
   "source": [
    "def split_sent(text, min_len=3, max_len=500):\n",
    "    res = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        sent = sent.split()\n",
    "        if len(sent) < max_len and len(sent) > min_len:\n",
    "            res.append(\" \".join(sent))\n",
    "    return res\n",
    "\n",
    "res = []\n",
    "for i, row in df.iterrows():\n",
    "    sents = split_sent(row['text'])\n",
    "    if not sents:\n",
    "        print(row['text'])\n",
    "    else:\n",
    "        for sent in sents:\n",
    "            res.append({\n",
    "              \"labels\": row[\"labels\"], \n",
    "              \"name\": row[\"name\"],\n",
    "              \"number\": row[\"number\"],\n",
    "              \"source\": row[\"source\"],\n",
    "              \"sent\": sent\n",
    "            })\n",
    "s = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = s[s['source'] == 'criminal_code']\n",
    "co = s[s['source'] == 'criminal_court_orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gzhigalov/miniconda3/envs/testing/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/gzhigalov/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/gzhigalov/.local/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "cc['vector'] = cc['sent'].map(sent_emb)\n",
    "co['vector'] = co['sent'].map(sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_train, co_test = train_test_split(co, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_space = scipy.spatial.KDTree(cc['vector'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = (\n",
    "    co.groupby(\"name\")\n",
    "    .agg({\n",
    "        \"labels\": \"first\", \n",
    "        \"source\": \"first\", \n",
    "        \"sent\": list, \n",
    "        \"vector\": list})\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 2.0]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.iloc[[1,2,3]]['number'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_by_sent(vectors, k=5):\n",
    "    res = []\n",
    "    for vec in vectors:\n",
    "        dist, idx = cc_space.query(vec, k=k)\n",
    "        articles = cc.iloc[idx][\"number\"].tolist()\n",
    "        res.append(list(zip(dist, articles)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co[\"labels\"] = co[\"labels\"].map(lambda x: list(map(float, x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co.to_csv('co.csv.gz', compression='gzip', index=False)\n",
    "cc.to_csv(\"cc.csv.gz\", compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
