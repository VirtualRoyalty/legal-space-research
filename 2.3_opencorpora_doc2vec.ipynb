{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gzhigalov/miniconda3/envs/testing/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import opencorpora\n",
    "from pymystem3 import Mystem\n",
    "from many_stop_words import get_stop_words\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_and_filter(text, min_len=3, stopwords=get_stop_words('ru'), stem=Mystem(entire_input=False)):\n",
    "    return ' '.join(list(filter(lambda word: word not in stopwords and len(word) > min_len, stem.lemmatize(text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opencorpora parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = opencorpora.CorpusReader('tmp/annot.opcorpora.xml')\n",
    "oc = pd.DataFrame([{\n",
    "    'title': d.title(), \n",
    "    'text': d.raw(), \n",
    "    'categories': d.categories(),\n",
    "    'lemmas': lemm_and_filter(d.raw())\n",
    "} for d in reader.iter_documents() if len(d.raw()) >= 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phraser = gensim.models.phrases.Phraser(gensim.models.phrases.Phrases(sentences=oc['lemmas'].str.split()))\n",
    "oc['phrased'] = oc['lemmas'].str.split().map(lambda x: ' '.join(phraser[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc.to_csv('tmp/opencorpora.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc = pd.read_csv('tmp/opencorpora.csv.gz', compression='gzip')\n",
    "criminal_code = pd.read_csv('tmp/vectors/criminal_code.csv.gz', compression='gzip')\n",
    "criminal_court_orders = pd.read_csv('tmp/vectors/criminal_court_orders.csv.gz', compression='gzip')\n",
    "civil_code = pd.read_csv('tmp/vectors/civil_code.csv.gz', compression='gzip')\n",
    "civil_court_orders = pd.read_csv('tmp/vectors/civil_court_orders.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc['source'] = 'opencorpora'\n",
    "criminal_code['source'] = 'criminal_code'\n",
    "criminal_court_orders['source'] = 'criminal_court_orders'\n",
    "civil_code['source'] = 'civil_code'\n",
    "civil_court_orders['source'] = 'civil_court_orders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criminal_code['name'] = criminal_code.apply(lambda x: \"Ст.{} {}\".format(x['article_number'], x['article_name']), axis=1)\n",
    "civil_code['name'] = civil_code.apply(lambda x: \"Ст.{} {}\".format(x['article_number'], x['article_name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "civil_court_orders['name'] = [\"Гражд. дело {}\".format(i) for i in range(civil_court_orders.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    oc.reset_index()[['index', 'title', 'phrased', 'source']].rename(columns={'title':'name'}), \n",
    "    criminal_code.reset_index()[['index', 'name', 'phrased', 'source']],\n",
    "    criminal_court_orders.reset_index()[['index', 'title', 'phrased',  'source']].rename(columns={'title':'name'}),\n",
    "    civil_code.reset_index()[['index', 'name', 'phrased', 'source']],\n",
    "    civil_court_orders.reset_index()[['index', 'name', 'phrased', 'source']],\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = lambda row: gensim.models.doc2vec.TaggedDocument(words=row['phrased'].split(), tags=[row.name])\n",
    "documents = df.apply(td, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.utils.save_as_line_sentence(df['phrased'].str.split(), 'tmp/phrased.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(\n",
    "    documents=gensim.models.doc2vec.TaggedLineDocument('tmp/phrased.txt'), \n",
    "    epochs=500, vector_size=300, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model = gensim.models.doc2vec.Doc2Vec()\n",
    "# model.build_vocab(documents)\n",
    "# model.train(documents, total_examples=model.corpus_count, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vectors'] = model.docvecs.vectors_docs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tmp/doc2vec/'):\n",
    "    os.mkdir('tmp/doc2vec')\n",
    "model.save('tmp/doc2vec/all_texts.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tmp/vectors/'):\n",
    "    os.mkdir('tmp/vectors')\n",
    "df.to_csv('tmp/vectors/all.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pca'] = PCA(n_components=2).fit_transform(df['vectors'].tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'pca'#'tsne'\n",
    "DISPLAY = ['civil_court_orders', 'criminal_court_orders', 'opencorpora', 'criminal_code', 'civil_code']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(11, 4), dpi=300, sharex='all', sharey='all')\n",
    "\n",
    "for source in df['source'].unique():\n",
    "    if source in DISPLAY:\n",
    "        tmp = np.array(df[df['source'] == source][METHOD].tolist())\n",
    "        ax1.scatter(tmp[:, 0], tmp[:, 1], marker='.', label=source, alpha=.4)\n",
    "        ax2 = sns.kdeplot(tmp[:, 0], tmp[:, 1], ax=ax2, legend=False, shade_lowest=False)\n",
    "        # ax2.text(-5, 8, \"Court Orders\", size=10, color='red')\n",
    "    \n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='both', which='both', left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "ax2.tick_params(axis='both', which='both', left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.autoscale()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'pca'#'tsne'\n",
    "DISPLAY = ['civil_court_orders', 'criminal_court_orders', 'opencorpora', 'criminal_code', 'civil_code']\n",
    "SAMPLE_SIZE = 200\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(15, 12), dpi=300)\n",
    "disable_ticks = lambda x: x.tick_params(axis='both', which='both', left=False, bottom=False, \n",
    "                                        labelleft=False, labelbottom=False)\n",
    "\n",
    "colors_iter = iter([\n",
    "    ('red', 'Reds'),\n",
    "    ('orange', 'Oranges'),\n",
    "    ('green', 'Greens'), \n",
    "    ('gray', 'Greys'), \n",
    "    ('purple', 'Purples'), \n",
    "    ('blue', 'Blues'), \n",
    "])\n",
    "\n",
    "for source_name in df['source'].unique():\n",
    "    if source_name in DISPLAY:\n",
    "        tmp = np.array(df[df['source'] == source_name][METHOD].tolist())\n",
    "        tmp_sample = np.array(df[df['source'] == source_name].sample(SAMPLE_SIZE)[METHOD].tolist())\n",
    "        color, colormap = next(colors_iter)\n",
    "        ax1.scatter(tmp_sample[:, 0], tmp_sample[:, 1], label=source_name, c=color)\n",
    "        sns.kdeplot(tmp[:, 0], tmp[:, 1], ax=ax2, shade=False, shade_lowest=False, cmap=colormap)\n",
    "        sns.kdeplot(tmp[:,0], ax=ax3, color=color)\n",
    "        sns.kdeplot(tmp[:, 1], ax=ax4, color=color)\n",
    "\n",
    "ax1.legend()\n",
    "ax3.legend()\n",
    "disable_ticks(ax1)\n",
    "disable_ticks(ax2)\n",
    "plt.tight_layout()\n",
    "plt.autoscale()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (testing)",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
